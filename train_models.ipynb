{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> <u>Jammer Classification: </u> </b>\n",
    "### Example Notebook Showing how you can train and save the modeles!\n",
    "### Step1: Import All Dependencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the dependencies from the requirements.txt\n",
    "\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Import tensor flow and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "# tensorflow hub is used to load the models\n",
    "!pip install -q tensorflow_hub\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import Matplot lib, Library to plot the results and graphs\n",
    "import matplotlib.pylab as plt \n",
    "\n",
    "# Argument parser to set variables\n",
    "import options\n",
    "\n",
    "# import dataloader\n",
    "from util import dataLoader\n",
    "\n",
    "# import generate model module\n",
    "from CNN import generate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Setup all Required Variables\n",
    "\n",
    "##### Delete sys.argv(req for ipython Kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to parse Argument from options.py\n",
    "import sys; sys.argv=['']; del sys\n",
    "args = options.parseArguments()\n",
    "\n",
    "#Set the mode to train or usePreTrain\n",
    "args.mode = \"usePreTrain\"\n",
    "args.freeze_feature_layers = True\n",
    "\n",
    "# Pre-Trained model to use\n",
    "args.pre_trained_model_name = \"inception_v3\"\n",
    "args.model_url = \"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(args.pre_trained_model_name)\n",
    "\n",
    "# Set the Dataset Directory\n",
    "args.input_dir = \"/media/aadmin/SamsungSSD/PROJECT-DATA/SIGENCE/Train_Val_Test/dataset/\"\n",
    "\n",
    "# Set the image Dimensions and batch size according to the pre-trained model's requirement Check it on tf-hub\n",
    "args.img_h = args.img_w = 299\n",
    "args.batch_size = 100\n",
    "\n",
    "# Set the load directory, where trained models and graphs are saved\n",
    "args.save_dir = \"./checkpoints/3_Classes/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Function for Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Pre Trained Models for Fine Tuning\n",
    "def usePreTrain(args):\n",
    "    # Generate Data Loader\n",
    "    dataloader = dataLoader.DataLoader(args)\n",
    "    train_data_gen, val_data_gen = dataloader.dataGenerator()\n",
    "    \n",
    "    #genrateModel\n",
    "    generateModel = generate_model.Generate_model(args, dataloader.num_classes)\n",
    "    model = generateModel.preTrainedModel()\n",
    "    \n",
    "    # Fit your Training Data\n",
    "    history = model.fit(train_data_gen, epochs=2, verbose=2,\n",
    "                steps_per_epoch= dataloader.num_train_images // args.batch_size)\n",
    "    \n",
    "    keras.experimental.export_saved_model(model, args.save_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DataLoader ...\n",
      "Looking for the data at --> /media/aadmin/SamsungSSD/PROJECT-DATA/SIGENCE/Train_Val_Test/dataset/\n",
      "Classes : ['01_ChirpJammerSignals', '04_NarrowBandSignals'] -----------\n",
      "Training Data Loader\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Validation Data Loader\n",
      "Found 400 images belonging to 2 classes.\n",
      "Do Fine Tuning of feature layers :  False\n",
      "Building model from -->  https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 21,806,882\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "Using SGD Optimizer for training\n",
      "Train on 5000 samples\n",
      "Epoch 1/2\n",
      "5000/5000 - 132s - loss: 0.7121 - accuracy: 0.9018\n",
      "Epoch 2/2\n",
      "5000/5000 - 120s - loss: 0.3340 - accuracy: 0.9874\n"
     ]
    }
   ],
   "source": [
    "if args.mode == \"usePreTrain\":\n",
    "    usePreTrain(args)\n",
    "\n",
    "elif args.mode==\"train\":\n",
    "    train(args)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
